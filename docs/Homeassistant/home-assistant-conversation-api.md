# Conversation API — Home Assistant Developer Docs

Intents can be recognized from text and fired using the conversation integration.

An API endpoint is available which receives an input sentence and produces a conversation response. A “conversation” is tracked across multiple inputs and responses by passing a `conversation_id` generated by Home Assistant.

The API is available via the REST API and WebSocket API.

---

## API Usage

### HTTP (REST)

Send a POST request to `/api/conversation/process`:

```json
{
  "text": "turn on the lights in the living room",
  "language": "en"
}
```

### WebSocket

You can also send via WebSocket:

```json
{
  "type": "conversation/process",
  "text": "turn on the lights in the living room",
  "language": "en"
}
```

#### Request fields

| Name             | Type     | Description                                                                 |
|------------------|----------|------------------------------------------------------------------------------|
| `text`           | string   | Input sentence.                                                              |
| `language`        | string   | Optional. Language of the input (defaults to configured language).         |
| `agent_id`        | string   | Optional. Conversation agent to process the request.                        |
| `conversation_id` | string   | Optional. Unique id to track multi‑turn conversation.                       |

---

## Conversation response

The JSON response from `/api/conversation/process` contains information about the intent effect and the speech / follow‑up.

Example:

```json
{
  "continue_conversation": true,
  "response": {
    "response_type": "action_done",
    "language": "en",
    "data": {
      "targets": [
        {
          "type": "area",
          "name": "Living Room",
          "id": "living_room"
        },
        {
          "type": "domain",
          "name": "light",
          "id": "light"
        }
      ],
      "success": [
        {
          "type": "entity",
          "name": "My Light",
          "id": "light.my_light"
        }
      ],
      "failed": []
    },
    "speech": {
      "plain": {
        "speech": "Turned Living Room lights on"
      }
    }
  },
  "conversation_id": "<generated-id-from-ha>"
}
```

---

## Response types

### action_done

Used when an intent triggered an action in Home Assistant (e.g. turning on a light). The `data` object includes:

- `targets`: list of general to specific targets (area, domain, device_class, device, entity, custom)
- `success`: entities/devices on which the action succeeded
- `failed`: entities/devices on which the action failed

Targets should be ordered from general to specific (e.g. area → domain → device → entity).

### query_answer

Used when the request is a question (e.g. “what is the temperature?”). The answer appears in `speech`, and relevant `data` is included.

Example:

```json
{
  "response": {
    "response_type": "query_answer",
    "language": "en",
    "speech": {
      "plain": {
        "speech": "It is 65 degrees"
      }
    },
    "data": {
      "targets": [
        {
          "type": "domain",
          "name": "climate",
          "id": "climate"
        }
      ],
      "success": [
        {
          "type": "entity",
          "name": "Ecobee",
          "id": "climate.ecobee"
        }
      ],
      "failed": []
    }
  },
  "conversation_id": "<generated-id-from-ha>"
}
```

### error

Used when intent recognition or execution fails. The `data` object contains `code`, and `speech` gives a message.

Possible `data.code` values:

- `no_intent_match` — input text did not match any intent  
- `no_valid_targets` — targeted area / entity does not exist  
- `failed_to_handle` — an unexpected error during handling  
- `unknown` — error outside intent processing scope  

Example:

```json
{
  "response": {
    "response_type": "error",
    "language": "en",
    "data": {
      "code": "no_intent_match"
    },
    "speech": {
      "plain": {
        "speech": "Sorry, I didn’t understand that"
      }
    }
  }
}
```

---

## Speech

The spoken response is provided via the `speech` property. It supports:

- **plain text** (default)  
- **SSML** — if SSML is used, the response includes a `ssml` field instead of `plain`.

Example plain:

```json
"speech": {
  "plain": {
    "speech": "...",
    "extra_data": null
  }
}
```

SSML example:

```json
"speech": {
  "ssml": {
    "speech": "...",
    "extra_data": null
  }
}
```

---

## Conversation Id

To support multi-turn conversations:

1. First request may omit `conversation_id`.  
2. The response returns `conversation_id`.  
3. For the next message, include the same `conversation_id` in the request.

Example:

- First message:

  ```json
  { "text": "Initial input sentence." }
  ```

- Response:

  ```json
  {
    "conversation_id": "<generated-id-from-ha>",
    "response": { ... }
  }
  ```

- Second message:

  ```json
  {
    "text": "Related input sentence.",
    "conversation_id": "<generated-id-from-ha>"
  }
  ```

---

## Pre‑loading sentences

You can pre‑load sentences for a language using WebSocket:

```json
{
  "type": "conversation/prepare",
  "language": "en"
}
```

Request fields:

| Name       | Type     | Description |
|------------|----------|-------------|
| `language`  | string   | Optional. Language to load sentences for. |

---

_Last updated on 2025-07-17. Source: https://developers.home-assistant.io/docs/intent_conversation_api/_
